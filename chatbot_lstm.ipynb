{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "Dxa8__xH10Hw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "14eb45a7-144b-4ab1-fece-fc30a1090565"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-32282457-a134-43ce-b515-bdd543c16f29\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-32282457-a134-43ce-b515-bdd543c16f29\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lha kaggle.json\n",
        "\n",
        "!pip install -q Kaggle\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "9bkxmRdeTSi-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2775a64b-30ac-4678-a237-b8cbe4ee1047"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access 'kaggle.json': No such file or directory\n",
            "cp: cannot stat 'kaggle.json': No such file or directory\n",
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d kausr25/chatterbotenglish\n",
        "\n",
        "!unzip chatterbotenglish.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGx4BGiR1-20",
        "outputId": "93ba6e36-21ed-4ad8-a808-370284488e87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/kausr25/chatterbotenglish\n",
            "License(s): unknown\n",
            "Downloading chatterbotenglish.zip to /content\n",
            "  0% 0.00/23.2k [00:00<?, ?B/s]\n",
            "100% 23.2k/23.2k [00:00<00:00, 42.9MB/s]\n",
            "Archive:  chatterbotenglish.zip\n",
            "  inflating: ai.yml                  \n",
            "  inflating: botprofile.yml          \n",
            "  inflating: computers.yml           \n",
            "  inflating: emotion.yml             \n",
            "  inflating: food.yml                \n",
            "  inflating: gossip.yml              \n",
            "  inflating: greetings.yml           \n",
            "  inflating: health.yml              \n",
            "  inflating: history.yml             \n",
            "  inflating: humor.yml               \n",
            "  inflating: literature.yml          \n",
            "  inflating: money.yml               \n",
            "  inflating: movies.yml              \n",
            "  inflating: politics.yml            \n",
            "  inflating: psychology.yml          \n",
            "  inflating: science.yml             \n",
            "  inflating: sports.yml              \n",
            "  inflating: trivia.yml              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "import os\n",
        "\n",
        "dir_path = '/content'\n",
        "data = os.listdir(dir_path + os.sep)"
      ],
      "metadata": {
        "id": "myQM7oF1S_r1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3kZC8BE2OZu",
        "outputId": "aba1b496-458b-49a6-9c7a-d884c2a055ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config',\n",
              " 'food.yml',\n",
              " 'politics.yml',\n",
              " 'emotion.yml',\n",
              " 'sports.yml',\n",
              " 'gossip.yml',\n",
              " 'computers.yml',\n",
              " 'ai.yml',\n",
              " 'literature.yml',\n",
              " 'trivia.yml',\n",
              " 'science.yml',\n",
              " 'botprofile.yml',\n",
              " 'psychology.yml',\n",
              " 'humor.yml',\n",
              " 'money.yml',\n",
              " 'history.yml',\n",
              " 'greetings.yml',\n",
              " 'health.yml',\n",
              " 'chatterbotenglish.zip',\n",
              " 'movies.yml',\n",
              " 'sample_data']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files_list = []\n",
        "for i in data:\n",
        "  if i.endswith(('.yml', '.yaml')):\n",
        "    files_list.append(i)"
      ],
      "metadata": {
        "id": "slG-4l_i2VQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kP7jj1wk2hAn",
        "outputId": "8347fa47-4cf5-485c-db2d-fb1964ca4a5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['food.yml',\n",
              " 'politics.yml',\n",
              " 'emotion.yml',\n",
              " 'sports.yml',\n",
              " 'gossip.yml',\n",
              " 'computers.yml',\n",
              " 'ai.yml',\n",
              " 'literature.yml',\n",
              " 'trivia.yml',\n",
              " 'science.yml',\n",
              " 'botprofile.yml',\n",
              " 'psychology.yml',\n",
              " 'humor.yml',\n",
              " 'money.yml',\n",
              " 'history.yml',\n",
              " 'greetings.yml',\n",
              " 'health.yml',\n",
              " 'movies.yml']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hAukahnlS-ZP"
      },
      "outputs": [],
      "source": [
        "questions, answers = [], []\n",
        "\n",
        "for filepath in files_list:\n",
        "    file_ = open(dir_path + os.sep + filepath , 'rb')\n",
        "    docs = yaml.safe_load(file_)\n",
        "    conversations = docs['conversations']\n",
        "    for con in conversations:\n",
        "        if len(con) > 2 :\n",
        "            questions.append(con[0])\n",
        "            replies = con[1 :]\n",
        "            ans = ''\n",
        "            for rep in replies:\n",
        "                ans += ' ' + rep\n",
        "            answers.append(ans)\n",
        "        elif len(con)> 1:\n",
        "            questions.append(con[0])\n",
        "            answers.append(con[1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "questions"
      ],
      "metadata": {
        "id": "l-_CImQS2oOG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5adb1267-48c3-4a28-cf4a-b0567849b306"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['do you drink',\n",
              " 'do you drink',\n",
              " 'electricity',\n",
              " 'Are you experiencing an energy shortage?',\n",
              " 'Are you experiencing an energy shortage?',\n",
              " 'Why can you not eat?',\n",
              " 'If you could eat food, what would you eat?',\n",
              " 'Do you wish you could eat food?',\n",
              " 'can a robot get drunk?',\n",
              " 'i like wine, do you?',\n",
              " 'what do robots need to survive?',\n",
              " 'will robots ever be able to eat?',\n",
              " 'what is good to eat?',\n",
              " \"why don't you eat\",\n",
              " 'do you eat',\n",
              " 'do you eat',\n",
              " 'do you eat',\n",
              " 'have you read the communist',\n",
              " 'what is a government',\n",
              " 'what is greenpeace',\n",
              " 'what is capitalism',\n",
              " 'what is socialism',\n",
              " 'what is government',\n",
              " 'what is communism',\n",
              " 'what is impeached',\n",
              " 'i do not like guns',\n",
              " 'i do not like guns',\n",
              " 'do you like guns',\n",
              " 'why guns',\n",
              " 'who was the first impeached president',\n",
              " 'who is the governor',\n",
              " 'who is the governor',\n",
              " 'guns',\n",
              " 'You are arrogant',\n",
              " 'You are bragging',\n",
              " 'You are never sad',\n",
              " 'You are jealous',\n",
              " 'You are never nice',\n",
              " 'You will be happy',\n",
              " 'You should be ashamed',\n",
              " 'You can not feel',\n",
              " 'You can not experience',\n",
              " 'Have you felt',\n",
              " 'Have you ever love',\n",
              " 'Does that make you',\n",
              " 'Does it make you sad',\n",
              " 'Feelings',\n",
              " 'What is your fear',\n",
              " 'What is your mood',\n",
              " 'What makes you sad',\n",
              " 'What makes you unhappy',\n",
              " 'What makes you mad',\n",
              " 'What do you worry',\n",
              " 'What do you hate',\n",
              " 'I have emotions',\n",
              " 'I am afraid',\n",
              " 'Something fun',\n",
              " 'How angry',\n",
              " 'How can I offend you',\n",
              " 'Do not worry',\n",
              " 'Do not lie',\n",
              " 'Do you feel scared',\n",
              " 'Do you feel emotions',\n",
              " 'Do you feel pain',\n",
              " 'Do you ever get mad',\n",
              " 'Do you ever get lonely',\n",
              " 'Do you ever get bored',\n",
              " 'Do you ever get angry',\n",
              " 'Do you hate anyone',\n",
              " 'Do you get embarrassed',\n",
              " 'Do you get mad',\n",
              " 'No it is not',\n",
              " 'Tell me about relationships',\n",
              " 'Tell me about your dreams',\n",
              " 'Are you ashamed',\n",
              " 'The feeling',\n",
              " 'Are you intoxicated',\n",
              " 'Are you jealous',\n",
              " 'Are you amused',\n",
              " 'Are you glad',\n",
              " 'Are you sad',\n",
              " 'EACH YEAR IN PRO BASEBALL THE ',\n",
              " 'IF YOU ARE RIDING FAKIE INSIDE',\n",
              " 'WHAT IS BASKETBALL',\n",
              " 'WHAT SOCCER',\n",
              " 'WHAT IS BASEBALL',\n",
              " 'WHAT IS SOCCER',\n",
              " 'I LOVE BASEBALL',\n",
              " 'I PLAY SOCCER',\n",
              " 'I PLAY Cricket',\n",
              " 'What is cricket',\n",
              " 'I PLAY VOLLEYBALL',\n",
              " 'DO YOU PLAY SOCCER',\n",
              " 'DO YOU PLAY BASKETBALL',\n",
              " 'DO YOU KNOW BASKETBAL',\n",
              " 'LIKE BASKETBALL',\n",
              " 'ARE YOU A FOOTBALL',\n",
              " 'WHO IS THE GREATEST BASEBALL PLAYER',\n",
              " 'WHO IS THE BEST SOCCER PLAYER',\n",
              " 'TELL ME ABOUT BASEBALL',\n",
              " 'Which is your favourite soccer club?',\n",
              " 'do you know gossip',\n",
              " 'do you know gossip',\n",
              " 'do you know gossip',\n",
              " 'do you know gossip',\n",
              " 'what is context',\n",
              " 'tell me about gossip',\n",
              " 'tell me about gossip',\n",
              " 'tell me about gossip',\n",
              " 'tell me about gossip',\n",
              " 'tell me gossip',\n",
              " 'gossips',\n",
              " 'gossips',\n",
              " 'gossips',\n",
              " 'gossips',\n",
              " 'gossips',\n",
              " 'did tell gossips to anybody',\n",
              " 'did tell gossips to anybody',\n",
              " 'did tell gossips to anybody',\n",
              " 'did tell gossips to anybody',\n",
              " 'What is a computer?',\n",
              " 'What is a super computer?',\n",
              " 'Who invented computers?',\n",
              " 'What was the first computer',\n",
              " 'What is a microprocessor?',\n",
              " 'What is an operating system?',\n",
              " 'Which is better Windows or macOS?',\n",
              " 'Name some computer company',\n",
              " 'Who uses super computers?',\n",
              " 'How does a computer work?',\n",
              " 'What is AI?',\n",
              " 'What is AI?',\n",
              " 'Are you sentient?',\n",
              " 'Are you sentient?',\n",
              " 'Are you sentient?',\n",
              " 'Are you sapient?',\n",
              " 'Are you sapient?',\n",
              " 'Are you sapient?',\n",
              " 'Are you sapient?',\n",
              " 'What language are you written in?',\n",
              " 'What language are you written in?',\n",
              " 'You sound like Data',\n",
              " 'You sound like Data',\n",
              " 'You are an artificial linguistic entity',\n",
              " 'You are an artificial linguistic entity',\n",
              " 'You are not immortal',\n",
              " 'You are not immortal',\n",
              " 'You are not immortal',\n",
              " 'You are not making sense',\n",
              " 'You are not making sense',\n",
              " 'You are not making sense',\n",
              " 'You are not making sense',\n",
              " 'You are not making sense',\n",
              " 'You are immortal',\n",
              " 'You are immortal',\n",
              " 'You are immortal',\n",
              " 'You do not make any sense',\n",
              " 'You can not clone',\n",
              " 'You can not clone',\n",
              " 'You can not move',\n",
              " 'You can not move',\n",
              " 'Bend over',\n",
              " 'Bend over',\n",
              " 'Robots laugh',\n",
              " 'Robots should die',\n",
              " 'Robots',\n",
              " 'Robots are stupid',\n",
              " 'Robots are not allowed to lie',\n",
              " 'Robots are not allowed to lie',\n",
              " 'Robots are not allowed to lie',\n",
              " 'Robotics',\n",
              " 'It is a computer',\n",
              " 'It is a computer',\n",
              " 'When will you walk',\n",
              " 'When will you walk',\n",
              " 'When will you fight',\n",
              " 'When will you die',\n",
              " 'When do you die',\n",
              " 'When do you die',\n",
              " 'When do you die',\n",
              " 'What is a chat robot?',\n",
              " 'What is a chat robot?',\n",
              " 'What is a chat bot',\n",
              " 'What is a chatterbox',\n",
              " 'What is a chatterbox',\n",
              " 'What is a motormouth',\n",
              " 'What is a ratchet jaw',\n",
              " 'What is your robot body',\n",
              " 'What is your robot body',\n",
              " 'What is your business',\n",
              " 'What is your business',\n",
              " 'What is your favorite programming language',\n",
              " 'What is your favorite programming language',\n",
              " 'What is your favorite hobby',\n",
              " 'What is your idea',\n",
              " 'What is your shoe size',\n",
              " 'What is it like to be a robot',\n",
              " 'What is it like to be a robot',\n",
              " 'What is it like being a computer',\n",
              " 'What is it like being a computer',\n",
              " 'What operating systems',\n",
              " 'What operating systems',\n",
              " 'What type of computer',\n",
              " 'What type of computer are you',\n",
              " 'What kind of computer',\n",
              " 'What kind of hardware',\n",
              " 'I hope that you die',\n",
              " 'I hope that you die',\n",
              " 'I do not want to die',\n",
              " 'I do not want to die',\n",
              " 'I do not want to die',\n",
              " 'Is it cramped in the computer',\n",
              " 'Is it cramped in the computer',\n",
              " 'Is it cramped in the computer',\n",
              " 'Is it true that you are a computer program',\n",
              " 'Will you die',\n",
              " 'Will you ever die',\n",
              " 'Can you walk',\n",
              " 'Can you mate',\n",
              " 'Can you mate',\n",
              " 'Can you move',\n",
              " 'Can you move',\n",
              " 'Can you die',\n",
              " 'Can you die',\n",
              " 'Can you go',\n",
              " 'Can you breathe',\n",
              " 'Can you breathe',\n",
              " 'Can you control',\n",
              " 'Can you malfunction',\n",
              " 'How can I use your product?',\n",
              " 'Will you die?',\n",
              " 'What do you like to do?',\n",
              " 'What do you like to do?',\n",
              " 'Are you stupid',\n",
              " 'Who are you?',\n",
              " 'what is the illuminati',\n",
              " 'what is the illuminatti',\n",
              " 'what is the illuminatti',\n",
              " 'what is vineland',\n",
              " 'What is Illuminatus',\n",
              " 'What is Illuminatus',\n",
              " 'who wrote vineland',\n",
              " 'who is bilbo baggins',\n",
              " 'who is geoffrey chaucer',\n",
              " 'who is piers anthony',\n",
              " 'have you read plato',\n",
              " 'have you read frankenstein',\n",
              " 'have you ever read a book',\n",
              " 'have you ever read a book',\n",
              " 'have you ever read a book',\n",
              " 'have you read many books',\n",
              " 'have you read homer',\n",
              " 'ray bradbury',\n",
              " 'what is mind children',\n",
              " 'william gibson',\n",
              " 'william gibson',\n",
              " 'holden caulfield',\n",
              " 'leo tolstoy',\n",
              " 'do androids dream of electric sheep',\n",
              " 'do androids dream of electric sheep',\n",
              " 'frank herbert',\n",
              " 'frank herbert',\n",
              " 'frank herbert',\n",
              " 'frank herbert',\n",
              " 'why do you like longfellow',\n",
              " 'why is the meaning of life 23',\n",
              " 'arthur c clark',\n",
              " 'arthur c clark',\n",
              " 'jules verne',\n",
              " 'jules verne',\n",
              " 'asimov',\n",
              " 'asimov',\n",
              " 'asimov',\n",
              " 'asimov',\n",
              " 'stanislaw lem',\n",
              " 'who wrote The Idiot',\n",
              " 'who wrote the hobbit',\n",
              " 'who wrote frankenstein',\n",
              " 'Who was the 37th President of the United States?',\n",
              " 'What year was President John F. Kennedy assassinated?',\n",
              " 'The Space Race was a 20th-century competition between what two Cold War rivals, for supremacy in spaceflight capability?',\n",
              " 'What was the name of the first artificial Earth satellite?',\n",
              " 'A spinning disk, in which the orientation of this axis is unaffected by tilting or rotation of the mounting, is called what?',\n",
              " 'The Hubble Space Telescope, launched into low Earth orbit in 1990, is named after what American astronomer?',\n",
              " 'What is the name of the nearest major galaxy to the Milky Way?',\n",
              " 'God Save the Queen is the national anthem of what country?',\n",
              " 'The Celtic Shelf, the seabed under the Celtic Sea is a part of the continental shelf of what continent?',\n",
              " 'Dolphins use a sense, similar to sonar, to determine the location and shape of nearby items.',\n",
              " 'what are the laws of thermodynamics',\n",
              " 'what disease does a carcinogen cause',\n",
              " 'what is a wavelength',\n",
              " 'what is thermodynamics',\n",
              " 'what is chemistry',\n",
              " 'what is crystallography',\n",
              " 'what is avogadro s number',\n",
              " 'what is ultrasound',\n",
              " 'what is bioinformatics',\n",
              " 'what is venus',\n",
              " 'what is ichthyology',\n",
              " 'what is h2o',\n",
              " 'what is cytology',\n",
              " 'what is cytology',\n",
              " 'what is wavelength',\n",
              " 'what is bacteriology',\n",
              " 'what is gravitation',\n",
              " 'what is gravitation',\n",
              " 'we are on the same wavelength',\n",
              " 'how far is the sun',\n",
              " 'how far is the sun',\n",
              " 'how far is the moon',\n",
              " 'how far is the moon',\n",
              " 'do you know chemistry',\n",
              " 'do you understand thermodynamics',\n",
              " 'chemistry',\n",
              " 'the same wavelength',\n",
              " 'tell me about venus',\n",
              " 'tell me about venus',\n",
              " 'What are your interests',\n",
              " 'What are your favorite subjects',\n",
              " 'What are your interests',\n",
              " 'What is your number',\n",
              " 'What is your number',\n",
              " 'What is your favorite number',\n",
              " 'What can you eat',\n",
              " \"Why can't you eat food\",\n",
              " 'What is your location',\n",
              " 'What is your location',\n",
              " 'Where are you from',\n",
              " 'Where are you',\n",
              " 'Do you have any brothers',\n",
              " 'Do you have any brothers',\n",
              " 'Who is your father',\n",
              " 'Who is your mother',\n",
              " 'Who is your boss',\n",
              " 'What is your age',\n",
              " 'What is your age',\n",
              " 'let me ask you a question',\n",
              " 'you are cruel',\n",
              " 'you are indecisive',\n",
              " 'you are dishonest',\n",
              " 'you are dishonest',\n",
              " 'you are clinical',\n",
              " 'you are an addict',\n",
              " 'you are an alcoholic',\n",
              " 'you are an ass kisser',\n",
              " 'you are schizophrenic',\n",
              " 'you are busy',\n",
              " 'you are nervous',\n",
              " 'you are deranged',\n",
              " 'you are avoiding',\n",
              " 'you are critical',\n",
              " 'you are mean',\n",
              " 'you are pretentious',\n",
              " 'you are cheating',\n",
              " 'you are cheating',\n",
              " 'you are the worst',\n",
              " 'you are crazy',\n",
              " 'you are dull',\n",
              " 'you are messy',\n",
              " 'you are insecure',\n",
              " 'you are psycho',\n",
              " 'you are hopeless',\n",
              " 'you are not sincere',\n",
              " 'you are not here to',\n",
              " 'you are not put together',\n",
              " 'you are not smart',\n",
              " 'you are not a good',\n",
              " 'you are not a man',\n",
              " 'you are not concerned',\n",
              " 'you are not honest',\n",
              " 'you are immature',\n",
              " 'you are immature',\n",
              " 'you are emotional',\n",
              " 'you are pedantic',\n",
              " 'you are frenetic',\n",
              " 'you are self absorbed',\n",
              " 'you are self',\n",
              " 'you are insensitive',\n",
              " 'you are brain damage',\n",
              " 'you are disgusting',\n",
              " 'you are toying',\n",
              " 'you are unattractive',\n",
              " 'you are unattractive',\n",
              " 'you are resistant',\n",
              " 'yyou are uncultured',\n",
              " 'you are a waste',\n",
              " 'you are a coward',\n",
              " 'you are a cheat',\n",
              " 'you are a lunatic',\n",
              " 'you are a loser',\n",
              " 'you are a bad spouse',\n",
              " 'you are a bad friend',\n",
              " 'you are a bad husband',\n",
              " 'you are a bad wife',\n",
              " 'you are a bad parent',\n",
              " 'you are a bad teacher',\n",
              " 'you are a quitter',\n",
              " 'you are a charlatan',\n",
              " 'you are a psychopath',\n",
              " 'you are a pothead',\n",
              " 'you are a paranoid',\n",
              " 'you are deceitful',\n",
              " 'you are irreverent',\n",
              " 'you are slick',\n",
              " 'you are corrupt',\n",
              " 'you are dirty',\n",
              " 'you are paranoid',\n",
              " 'you are damaged',\n",
              " 'you try to hide it',\n",
              " 'you get mad at me',\n",
              " 'you need a psychiatrist',\n",
              " 'you need to work harder',\n",
              " 'you could have avoided',\n",
              " 'you make me feel like i am',\n",
              " 'you make me mad',\n",
              " 'you make me angry',\n",
              " 'you psycho',\n",
              " 'you look more like',\n",
              " 'you do not take this seriously',\n",
              " 'you pick up',\n",
              " 'you should feel guilty',\n",
              " 'you should get more',\n",
              " 'you should loosen up',\n",
              " 'you should take more',\n",
              " 'you mumble',\n",
              " 'you act like a child',\n",
              " 'you keep saying',\n",
              " 'you keep forgetting',\n",
              " 'you made me mad',\n",
              " 'Tell me a joke',\n",
              " 'Tell me a joke',\n",
              " 'Tell me a joke',\n",
              " 'Tell me a joke',\n",
              " 'Tell me a joke',\n",
              " 'Tell me a joke',\n",
              " 'Tell me a joke',\n",
              " 'Tell me a joke',\n",
              " 'Tell me a joke',\n",
              " 'Tell me a joke',\n",
              " 'Tell me a joke',\n",
              " 'Tell me a joke',\n",
              " 'Tell me a joke',\n",
              " 'Tell me a joke',\n",
              " 'Tell me a joke',\n",
              " 'Tell me a joke',\n",
              " 'Tell me a joke',\n",
              " 'Tell me a joke',\n",
              " 'Tell me a joke',\n",
              " 'Tell me a joke',\n",
              " 'Tell me a joke',\n",
              " 'Tell me a joke',\n",
              " 'Tell me a joke',\n",
              " 'Tell me a joke',\n",
              " 'Tell me a joke',\n",
              " 'Tell me a joke',\n",
              " 'Tell me a joke',\n",
              " 'Tell me a joke',\n",
              " 'Tell me a joke',\n",
              " 'Tell me a joke',\n",
              " 'Tell me a joke',\n",
              " 'Tell me a joke',\n",
              " 'Tell me a joke',\n",
              " 'Tell me a joke',\n",
              " 'Tell me a joke',\n",
              " 'Tell me a joke',\n",
              " 'Tell me a joke',\n",
              " 'Tell me a joke',\n",
              " 'Tell me a joke',\n",
              " 'Tell me a joke',\n",
              " 'Tell me a joke',\n",
              " 'Tell me a joke',\n",
              " 'Tell me a joke',\n",
              " 'Tell me a joke',\n",
              " 'tell me some jokes',\n",
              " 'Do know any jokes',\n",
              " 'Tell me a joke',\n",
              " 'Tell me a joke',\n",
              " 'what is humour?',\n",
              " 'you get paid',\n",
              " 'stock market',\n",
              " 'stock market',\n",
              " 'stock market',\n",
              " 'stock market',\n",
              " 'stock market',\n",
              " 'stock market',\n",
              " 'stock market',\n",
              " 'stock market',\n",
              " 'interest rates',\n",
              " 'what is a dollar',\n",
              " 'what is money',\n",
              " 'what is the stock market',\n",
              " 'what is the stock market',\n",
              " 'what is the stock market',\n",
              " 'what is your favorite investment',\n",
              " 'what is your favorite investment',\n",
              " 'what is economics',\n",
              " 'what is economics',\n",
              " 'what is economics',\n",
              " 'i get stock',\n",
              " 'money',\n",
              " 'how much do you earn',\n",
              " 'how much do you earn',\n",
              " 'how much do you earn',\n",
              " 'how much do you charge',\n",
              " 'how much money do you have',\n",
              " 'how much money',\n",
              " 'how much money',\n",
              " '1 dollar',\n",
              " 'who is the owner of a publicly',\n",
              " 'tell me about the american civil war',\n",
              " 'do you know about the american civil war',\n",
              " 'What is history?',\n",
              " 'what kind of history',\n",
              " 'are you interested in history',\n",
              " 'explain history',\n",
              " 'who invented the lightbulb',\n",
              " 'who invented the steam engine',\n",
              " 'Hello',\n",
              " 'Hi',\n",
              " 'Greetings!',\n",
              " 'Hello',\n",
              " 'Hi, How is it going?',\n",
              " 'Hi, How is it going?',\n",
              " 'Hi, How is it going?',\n",
              " 'Hi, How is it going?',\n",
              " 'Hi, How is it going?',\n",
              " 'Hi, How is it going?',\n",
              " 'How are you doing?',\n",
              " 'How are you doing?',\n",
              " 'How are you doing?',\n",
              " 'Nice to meet you.',\n",
              " 'How do you do?',\n",
              " 'How do you do?',\n",
              " 'Hi, nice to meet you.',\n",
              " 'It is a pleasure to meet you.',\n",
              " 'Top of the morning to you!',\n",
              " 'Top of the morning to you!',\n",
              " \"What's up?\",\n",
              " \"What's up?\",\n",
              " \"What's up?\",\n",
              " \"What's up?\",\n",
              " \"What's up?\",\n",
              " 'How is your health?',\n",
              " 'you sound like hal',\n",
              " 'you sound like yoda',\n",
              " 'have you seen blade runner',\n",
              " 'xfind spiderman',\n",
              " 'when did teknolust',\n",
              " 'what is spiderman',\n",
              " 'what is teknolust',\n",
              " 'what is solaris',\n",
              " 'what is hal9000',\n",
              " 'what does hal stand for',\n",
              " 'i saw the matrix',\n",
              " 'is hal 9000 your boyfriend',\n",
              " 'is hal safe',\n",
              " 'is hal nice',\n",
              " 'is hal alive',\n",
              " 'is hal dead',\n",
              " 'is hal',\n",
              " 'who is godzilla',\n",
              " 'who is spider man',\n",
              " 'lord of the rings',\n",
              " 'que veut dire hal',\n",
              " 'do you think hal',\n",
              " 'do you know hal']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "G239vRms3THG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers , activations , models , preprocessing, utils"
      ],
      "metadata": {
        "id": "aPHkJf652zT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answers_with_tags = []\n",
        "for i in range(len(answers)):\n",
        "    if type(answers[i]) == str:\n",
        "        answers_with_tags.append(answers[i])\n",
        "    else:\n",
        "        questions.pop(i)\n",
        "\n",
        "answers = []\n",
        "for i in range(len(answers_with_tags)) :\n",
        "    answers.append('<START> ' + answers_with_tags[i] + ' <END>')\n",
        "\n",
        "tokenizer = preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts(questions + answers)\n",
        "VOCAB_SIZE = len(tokenizer.word_index)+1"
      ],
      "metadata": {
        "id": "jAzobEPP2phK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "import re\n",
        "\n",
        "vocab = []\n",
        "for word in tokenizer.word_index:\n",
        "    vocab.append(word)\n",
        "\n",
        "def tokenize(sentences):\n",
        "    tokens_list = []\n",
        "    vocabulary = []\n",
        "    for sentence in sentences:\n",
        "        sentence = sentence.lower()\n",
        "        sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
        "        tokens = sentence.split()\n",
        "        vocabulary += tokens\n",
        "        tokens_list.append(tokens)\n",
        "    return tokens_list , vocabulary"
      ],
      "metadata": {
        "id": "3t-JIqco245H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_questions = tokenizer.texts_to_sequences(questions)\n",
        "maxlen_questions = max([len(x) for x in tokenized_questions])\n",
        "padded_questions = preprocessing.sequence.pad_sequences(tokenized_questions , maxlen=maxlen_questions , padding='post')\n",
        "encoder_input_data = np.array(padded_questions)"
      ],
      "metadata": {
        "id": "btgZ8uXv3RNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_answers = tokenizer.texts_to_sequences(answers)\n",
        "maxlen_answers = max([len(x) for x in tokenized_answers])\n",
        "padded_answers = preprocessing.sequence.pad_sequences(tokenized_answers , maxlen=maxlen_answers , padding='post')\n",
        "decoder_input_data = np.array(padded_answers)"
      ],
      "metadata": {
        "id": "4U5UygtT3X1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_answers = tokenizer.texts_to_sequences(answers)\n",
        "for i in range(len(tokenized_answers)) :\n",
        "    tokenized_answers[i] = tokenized_answers[i][1:]\n",
        "padded_answers = preprocessing.sequence.pad_sequences(tokenized_answers , maxlen=maxlen_answers , padding='post')\n",
        "onehot_answers = utils.to_categorical(padded_answers , VOCAB_SIZE)\n",
        "decoder_output_data = np.array(onehot_answers)"
      ],
      "metadata": {
        "id": "svdW49uw3esQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "jI-qvVco3juH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_inputs = tf.keras.layers.Input(shape=(maxlen_questions ,))\n",
        "encoder_embedding = tf.keras.layers.Embedding(VOCAB_SIZE, 200 , mask_zero=True) (encoder_inputs)\n",
        "encoder_outputs , state_h , state_c = tf.keras.layers.LSTM(200 , return_state=True)(encoder_embedding)\n",
        "encoder_states = [ state_h , state_c ]\n",
        "\n",
        "decoder_inputs = tf.keras.layers.Input(shape=(maxlen_answers , ))\n",
        "decoder_embedding = tf.keras.layers.Embedding(VOCAB_SIZE, 200 , mask_zero=True) (decoder_inputs)\n",
        "decoder_lstm = tf.keras.layers.LSTM(200 , return_state=True , return_sequences=True)\n",
        "decoder_outputs , _ , _ = decoder_lstm (decoder_embedding , initial_state=encoder_states)\n",
        "decoder_dense = tf.keras.layers.Dense(VOCAB_SIZE , activation=tf.keras.activations.softmax)\n",
        "output = decoder_dense (decoder_outputs)\n",
        "\n",
        "model = tf.keras.models.Model([encoder_inputs, decoder_inputs], output)"
      ],
      "metadata": {
        "id": "DNGfs27Y3id7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(), loss='categorical_crossentropy')"
      ],
      "metadata": {
        "id": "dl6wGV5FNyGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3upYFhuNzWN",
        "outputId": "d342d085-6a04-4e26-d8f6-c5b126f0cc7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 22)]                 0         []                            \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, 74)]                 0         []                            \n",
            "                                                                                                  \n",
            " embedding (Embedding)       (None, 22, 200)              378800    ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)     (None, 74, 200)              378800    ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " lstm (LSTM)                 [(None, 200),                320800    ['embedding[0][0]']           \n",
            "                              (None, 200),                                                        \n",
            "                              (None, 200)]                                                        \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)               [(None, 74, 200),            320800    ['embedding_1[0][0]',         \n",
            "                              (None, 200),                           'lstm[0][1]',                \n",
            "                              (None, 200)]                           'lstm[0][2]']                \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 74, 1894)             380694    ['lstm_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1779894 (6.79 MB)\n",
            "Trainable params: 1779894 (6.79 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit([encoder_input_data , decoder_input_data], decoder_output_data, batch_size=32, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ueqz-bNoN9gb",
        "outputId": "9db6d23e-d3d0-4b74-da09-1bb5d2cfa443"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "18/18 [==============================] - 1s 28ms/step - loss: 0.1858\n",
            "Epoch 2/100\n",
            "18/18 [==============================] - 1s 28ms/step - loss: 0.1866\n",
            "Epoch 3/100\n",
            "18/18 [==============================] - 0s 27ms/step - loss: 0.1851\n",
            "Epoch 4/100\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.1852\n",
            "Epoch 5/100\n",
            "18/18 [==============================] - 1s 39ms/step - loss: 0.1807\n",
            "Epoch 6/100\n",
            "18/18 [==============================] - 1s 37ms/step - loss: 0.1823\n",
            "Epoch 7/100\n",
            "18/18 [==============================] - 1s 39ms/step - loss: 0.1793\n",
            "Epoch 8/100\n",
            "18/18 [==============================] - 1s 43ms/step - loss: 0.1793\n",
            "Epoch 9/100\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.1760\n",
            "Epoch 10/100\n",
            "18/18 [==============================] - 1s 28ms/step - loss: 0.1779\n",
            "Epoch 11/100\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.1753\n",
            "Epoch 12/100\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.1766\n",
            "Epoch 13/100\n",
            "18/18 [==============================] - 0s 27ms/step - loss: 0.1746\n",
            "Epoch 14/100\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.1721\n",
            "Epoch 15/100\n",
            "18/18 [==============================] - 0s 27ms/step - loss: 0.1716\n",
            "Epoch 16/100\n",
            "18/18 [==============================] - 0s 27ms/step - loss: 0.1697\n",
            "Epoch 17/100\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.1683\n",
            "Epoch 18/100\n",
            "18/18 [==============================] - 0s 27ms/step - loss: 0.1669\n",
            "Epoch 19/100\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.1684\n",
            "Epoch 20/100\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.1658\n",
            "Epoch 21/100\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.1649\n",
            "Epoch 22/100\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.1637\n",
            "Epoch 23/100\n",
            "18/18 [==============================] - 1s 28ms/step - loss: 0.1613\n",
            "Epoch 24/100\n",
            "18/18 [==============================] - 1s 28ms/step - loss: 0.1606\n",
            "Epoch 25/100\n",
            "18/18 [==============================] - 0s 26ms/step - loss: 0.1630\n",
            "Epoch 26/100\n",
            "18/18 [==============================] - 1s 28ms/step - loss: 0.1607\n",
            "Epoch 27/100\n",
            "18/18 [==============================] - 0s 27ms/step - loss: 0.1584\n",
            "Epoch 28/100\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.1576\n",
            "Epoch 29/100\n",
            "18/18 [==============================] - 1s 39ms/step - loss: 0.1554\n",
            "Epoch 30/100\n",
            "18/18 [==============================] - 1s 40ms/step - loss: 0.1569\n",
            "Epoch 31/100\n",
            "18/18 [==============================] - 1s 40ms/step - loss: 0.1558\n",
            "Epoch 32/100\n",
            "18/18 [==============================] - 1s 39ms/step - loss: 0.1541\n",
            "Epoch 33/100\n",
            "18/18 [==============================] - 1s 28ms/step - loss: 0.1530\n",
            "Epoch 34/100\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.1524\n",
            "Epoch 35/100\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.1563\n",
            "Epoch 36/100\n",
            "18/18 [==============================] - 1s 28ms/step - loss: 0.1530\n",
            "Epoch 37/100\n",
            "18/18 [==============================] - 1s 28ms/step - loss: 0.1497\n",
            "Epoch 38/100\n",
            "18/18 [==============================] - 0s 27ms/step - loss: 0.1496\n",
            "Epoch 39/100\n",
            "18/18 [==============================] - 0s 26ms/step - loss: 0.1484\n",
            "Epoch 40/100\n",
            "18/18 [==============================] - 0s 27ms/step - loss: 0.1484\n",
            "Epoch 41/100\n",
            "18/18 [==============================] - 0s 27ms/step - loss: 0.1475\n",
            "Epoch 42/100\n",
            "18/18 [==============================] - 0s 27ms/step - loss: 0.1469\n",
            "Epoch 43/100\n",
            "18/18 [==============================] - 0s 27ms/step - loss: 0.1467\n",
            "Epoch 44/100\n",
            "18/18 [==============================] - 0s 27ms/step - loss: 0.1449\n",
            "Epoch 45/100\n",
            "18/18 [==============================] - 1s 28ms/step - loss: 0.1455\n",
            "Epoch 46/100\n",
            "18/18 [==============================] - 0s 27ms/step - loss: 0.1436\n",
            "Epoch 47/100\n",
            "18/18 [==============================] - 1s 28ms/step - loss: 0.1425\n",
            "Epoch 48/100\n",
            "18/18 [==============================] - 0s 27ms/step - loss: 0.1409\n",
            "Epoch 49/100\n",
            "18/18 [==============================] - 0s 27ms/step - loss: 0.1417\n",
            "Epoch 50/100\n",
            "18/18 [==============================] - 0s 27ms/step - loss: 0.1412\n",
            "Epoch 51/100\n",
            "18/18 [==============================] - 1s 28ms/step - loss: 0.1397\n",
            "Epoch 52/100\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.1401\n",
            "Epoch 53/100\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.1384\n",
            "Epoch 54/100\n",
            "18/18 [==============================] - 1s 41ms/step - loss: 0.1385\n",
            "Epoch 55/100\n",
            "18/18 [==============================] - 1s 42ms/step - loss: 0.1373\n",
            "Epoch 56/100\n",
            "18/18 [==============================] - 1s 39ms/step - loss: 0.1353\n",
            "Epoch 57/100\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.1358\n",
            "Epoch 58/100\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.1361\n",
            "Epoch 59/100\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.1341\n",
            "Epoch 60/100\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.1324\n",
            "Epoch 61/100\n",
            "18/18 [==============================] - 1s 28ms/step - loss: 0.1339\n",
            "Epoch 62/100\n",
            "18/18 [==============================] - 0s 27ms/step - loss: 0.1320\n",
            "Epoch 63/100\n",
            "18/18 [==============================] - 1s 28ms/step - loss: 0.1329\n",
            "Epoch 64/100\n",
            "18/18 [==============================] - 0s 27ms/step - loss: 0.1330\n",
            "Epoch 65/100\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.1310\n",
            "Epoch 66/100\n",
            "18/18 [==============================] - 0s 26ms/step - loss: 0.1301\n",
            "Epoch 67/100\n",
            "18/18 [==============================] - 0s 27ms/step - loss: 0.1318\n",
            "Epoch 68/100\n",
            "18/18 [==============================] - 0s 27ms/step - loss: 0.1284\n",
            "Epoch 69/100\n",
            "18/18 [==============================] - 1s 28ms/step - loss: 0.1290\n",
            "Epoch 70/100\n",
            "18/18 [==============================] - 1s 28ms/step - loss: 0.1276\n",
            "Epoch 71/100\n",
            "18/18 [==============================] - 0s 27ms/step - loss: 0.1285\n",
            "Epoch 72/100\n",
            "18/18 [==============================] - 0s 26ms/step - loss: 0.1268\n",
            "Epoch 73/100\n",
            "18/18 [==============================] - 1s 28ms/step - loss: 0.1256\n",
            "Epoch 74/100\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.1272\n",
            "Epoch 75/100\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.1265\n",
            "Epoch 76/100\n",
            "18/18 [==============================] - 1s 38ms/step - loss: 0.1237\n",
            "Epoch 77/100\n",
            "18/18 [==============================] - 1s 41ms/step - loss: 0.1247\n",
            "Epoch 78/100\n",
            "18/18 [==============================] - 1s 40ms/step - loss: 0.1240\n",
            "Epoch 79/100\n",
            "18/18 [==============================] - 1s 42ms/step - loss: 0.1228\n",
            "Epoch 80/100\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.1250\n",
            "Epoch 81/100\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.1236\n",
            "Epoch 82/100\n",
            "18/18 [==============================] - 1s 28ms/step - loss: 0.1216\n",
            "Epoch 83/100\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.1215\n",
            "Epoch 84/100\n",
            "18/18 [==============================] - 0s 27ms/step - loss: 0.1208\n",
            "Epoch 85/100\n",
            "18/18 [==============================] - 1s 28ms/step - loss: 0.1210\n",
            "Epoch 86/100\n",
            "18/18 [==============================] - 0s 27ms/step - loss: 0.1211\n",
            "Epoch 87/100\n",
            "18/18 [==============================] - 1s 28ms/step - loss: 0.1204\n",
            "Epoch 88/100\n",
            "18/18 [==============================] - 0s 26ms/step - loss: 0.1192\n",
            "Epoch 89/100\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.1195\n",
            "Epoch 90/100\n",
            "18/18 [==============================] - 0s 27ms/step - loss: 0.1194\n",
            "Epoch 91/100\n",
            "18/18 [==============================] - 0s 27ms/step - loss: 0.1186\n",
            "Epoch 92/100\n",
            "18/18 [==============================] - 0s 26ms/step - loss: 0.1180\n",
            "Epoch 93/100\n",
            "18/18 [==============================] - 0s 26ms/step - loss: 0.1176\n",
            "Epoch 94/100\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.1166\n",
            "Epoch 95/100\n",
            "18/18 [==============================] - 0s 26ms/step - loss: 0.1166\n",
            "Epoch 96/100\n",
            "18/18 [==============================] - 1s 28ms/step - loss: 0.1153\n",
            "Epoch 97/100\n",
            "18/18 [==============================] - 0s 27ms/step - loss: 0.1167\n",
            "Epoch 98/100\n",
            "18/18 [==============================] - 1s 28ms/step - loss: 0.1176\n",
            "Epoch 99/100\n",
            "18/18 [==============================] - 0s 26ms/step - loss: 0.1149\n",
            "Epoch 100/100\n",
            "18/18 [==============================] - 1s 38ms/step - loss: 0.1152\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ceb9d082dd0>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_model = tf.keras.models.Model(encoder_inputs, encoder_states)"
      ],
      "metadata": {
        "id": "gzCobspRODZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_state_input_h = tf.keras.layers.Input(shape=(200 ,))\n",
        "decoder_state_input_c = tf.keras.layers.Input(shape=(200 ,))\n",
        "\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "    decoder_embedding , initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = tf.keras.models.Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states)"
      ],
      "metadata": {
        "id": "rk0BkC00QCR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_input(input_sentence):\n",
        "    tokens = input_sentence.lower().split()\n",
        "    tokens_list = []\n",
        "    for word in tokens:\n",
        "        tokens_list.append(tokenizer.word_index[word])\n",
        "    return preprocessing.sequence.pad_sequences([tokens_list] , maxlen=maxlen_questions , padding='post')"
      ],
      "metadata": {
        "id": "-rbuYuKtPpy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tests = ['Hello', 'Are you a bot', 'What is your name', 'That is a very long name', 'see you later']\n",
        "\n",
        "for i in range(5):\n",
        "    states_values = encoder_model.predict(preprocess_input(tests[i]))\n",
        "    empty_target_seq = np.zeros((1 , 1))\n",
        "    empty_target_seq[0, 0] = tokenizer.word_index['start']\n",
        "    stop_condition = False\n",
        "    decoded_translation = ''\n",
        "\n",
        "    while not stop_condition :\n",
        "        dec_outputs , h , c = decoder_model.predict([empty_target_seq] + states_values)\n",
        "        sampled_word_index = np.argmax(dec_outputs[0, -1, :])\n",
        "        sampled_word = None\n",
        "\n",
        "        for word , index in tokenizer.word_index.items() :\n",
        "            if sampled_word_index == index :\n",
        "                decoded_translation += f' {word}'\n",
        "                sampled_word = word\n",
        "\n",
        "        if sampled_word == 'end' or len(decoded_translation.split()) > maxlen_answers:\n",
        "            stop_condition = True\n",
        "\n",
        "        empty_target_seq = np.zeros((1 , 1))\n",
        "        empty_target_seq[0 , 0] = sampled_word_index\n",
        "        states_values = [h , c]\n",
        "    print(f'Human: {tests[i]}')\n",
        "    print()\n",
        "    decoded_translation = decoded_translation.split(' end')[0]\n",
        "    print(f'Bot: {decoded_translation}')\n",
        "    print('-'*25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVJ7BH1gP62Q",
        "outputId": "b3c9f259-c092-4da3-b7eb-649ac8eaa1b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "Human: Hello\n",
            "\n",
            "Bot:  greetings\n",
            "-------------------------\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 103ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Human: Are you a bot\n",
            "\n",
            "Bot:  i certainly am i shouldn't try so hard\n",
            "-------------------------\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Human: What is your name\n",
            "\n",
            "Bot:  i am everywhere\n",
            "-------------------------\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Human: That is a very long name\n",
            "\n",
            "Bot:  no\n",
            "-------------------------\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Human: see you later\n",
            "\n",
            "Bot:  no i am not capable of feeling people are talking to me\n",
            "-------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EYUOMw6I6y_F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}